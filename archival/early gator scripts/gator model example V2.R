# Author: Brian Waismeyer
# Contact: bwaismeyer@gmail.com

# Date created: 3/20/2015
# Date updated: 3/23/2015

###############################################################################
## SCRIPT OVERVIEW

# goal: Prototype that fits a multinomial logit model to given data and then
#       does a set of simulations to generate predictions for the the outcomes
#       across the range of a given predictor.
#
#       The model fitting and prediction generation is handled by the simcf 
#       package and the example code described in the help docs for the 
#       mlogitsimev function from that package. 
#
#       Where to find the original example code:
#       library(simcf)
#       help(mlogitsimev)
#
#       The original example code was vague, limited and somewhat broken. It has
#       been corrected, extended, and made into a function set (performance 
#       testable) for this prototype.
#
#       The simulated data generated by the example is then visualized via
#       ggplot2, sensitive to user input regarding what predictors should
#       be used for the x-axis and/or faceting.
#
#       Our goal is to take this example and build a Shiny package on top of it.
#       We will explore how efficient it will be to simulate data from a 
#       multonomial logit model and and visualize the results on the fly via 
#       Shiny.

# sketch of script
# - LOAD SUPPORTING LIBRARIES
#
# - LOAD EXAMPLE DATA AND GET MODEL OBJECT
#   - only useful for the prototype itself (will provide model prebuilt 
#     for the final product)
#
# - FUNCTIONs TO GENERATE OUTCOME PREDICTIONS FOR GIVEN MODEL OBJECT
#   - extract point estimates from the model object
#   - solve for the covariance matrix
#   - get coefficient estimates via simulation
#   - generate data to feed to coefficient estimates
#   - get the outcome predictions (feed the estimates!)
#
# - FUNCTIONs TO VISUALIZE OUTCOME PREDICTIONS (USER SELECTED X-AXIS/FACETTING)
#   - 
#
# - WRAPPER FUNCTION FOR SIMULATION AND VISUALIZATION
#   - make sure inputs are sensible (model object, original data to get ranges,
#     x-axis choice, facet choice, number of param sims, range sampling density)

###############################################################################
## LOAD SUPPORTING LIBRARIES
#   - to get simcf (a custom package on github), use the install_github 
#     function from the devtools package:
#     install_github("chrisadolph/tile-simcf", subdir = "simcf")

library(nnet)       # processes the multinomial logit
library(MASS)       # allows for multivariate sampling
library(simcf)      # creates counterfactual sets (and provides example data)
library(tidyr)      # for reformatting data for visualization
library(ggplot2)    # for visualizing the data

###############################################################################
## LOAD EXAMPLE DATA AND GET MODEL OBJECT
#   - the gator dataset comes from the simcf package (the original doc fails
#     to specify this and loaded it out of order)

# load the data
data(gator)

# adding a new continuous predictor: number of teeth
# (seed set to insure consistency during prototyping then unset to insure no interference with later
#  random number generation)
set.seed(1)
teeth <- round(runif(59, 13, 30))
set.seed = NULL

# gather into a properly formatted dataframe (useful for proper handling
# of variables later when determining variable ranges)
gator <- data.frame(food, size, sex = female, teeth)
gator$food <- factor(gator$food, 
                     levels = c(1, 2, 3), 
                     labels = c("reunification", "adoption", "guardianship"))
gator$sex <- factor(gator$sex, 
                    levels = c(0, 1), 
                    labels = c("male", "female"))

# quick clean-up of the no longer needed data objects
rm(female, food, set.seed, size, teeth)

# multinom: "fit a multinomial log-linear model via neural networks"
gator_logit <- multinom(food ~ size + sex + teeth, 
                        data = gator, Hess=TRUE)

# alternate test model with an interaction term
int_logit <- multinom(food ~ size + sex + teeth + size * teeth, 
                      data = gator, Hess=TRUE)

###############################################################################
## FUNCTIONs TO GENERATE OUTCOME PREDICTIONS FOR GIVEN MODEL OBJECT
#   - extract point estimates from the model object
#   - solve for the covariance matrix
#   - get coefficient estimates via simulation
#   - generate data to feed to coefficient estimates
#   - get the outcome predictions (feed the estimates!)

# function to extract non-reference point estimates from the model object
get_point_estimates <- function(model_object) {
    # determine the number of coefficents (intercepts, predictors, interactions) 
    # and outcomes
    number_coefficients <- length(model_object$coefnames)
    number_outcomes <- length(model_object$lab)
    
    # the multinom function returns a lot of 0s - first we find identify where the
    # non-reference weights begin (one set of weights per outcome but we 
    # skip the initial reference set)
    index_starts <- NULL
    for(i in 1:(number_outcomes - 1)) {
        # go the end of the current chunk... add two to skip the placeholder 0...
        index_starts[i] <- i * (number_coefficients + 1) + 2
    }
    
    # then we use the start indices and the the number of coefficients to
    # define the index that will align with all the non-reference weights
    wts_index <- NULL
    for(i in index_starts) {
        wts_index <- c(wts_index, i:(i + number_coefficients - 1))
    }
    
    # finally we return the point estimates (weights) for the coefficients
    return(model_object$wts[wts_index])
}

# function to get the covariance matrix from the Hessian in the model object
get_covariance_matrix <- function(model_object) {
    solve(model_object$Hess)
}

# function to get coefficient estimates via simulation
get_coefficient_estimates <- function(sample_size, 
                                      point_estimates, 
                                      covariance_matrix,
                                      number_outcomes) {
    # draw parameters, using MASS::mvrnorm
    sim_betas <- mvrnorm(sample_size, point_estimates, covariance_matrix)
    
    # data needs to be re-arranged into an array format
    # first determine array dimensions...
    number_arrays  <- number_outcomes - 1
    number_columns <- length(point_estimates)/number_arrays
    number_rows    <- sample_size
    
    # then re-arrange simulates to array format for MNL simulation
    sim_beta_array <- array(NA, dim = c(number_rows, 
                                        number_columns, 
                                        number_arrays)
                            )  
    index_starts <- seq(from = 1, to = number_columns * number_arrays, 
                        by = number_columns)
    for(i in 1:number_arrays) {
        sim_beta_array[, , i] <- sim_betas[, index_starts[i]:(index_starts[i] + number_columns - 1)]
    }
    
    # return the re-arranged coefficient estimates
    return(sim_beta_array)
}

# generate data to feed the coefficient estimates
get_new_data <- function(dataset, model_object,
                         x_axis_variable, x_range = NULL, x_range_density = 100,
                         facet_variable = NULL) {
    # check if an explicit range has been provided for the x-axis variable
    if(is.null(x_range)) {
        # if not provided, calculate the range from the dataset
        # floor and ceiling used to insure some space around the observed data
        x_range[1] <- floor(min(dataset[x_axis_variable]))
        x_range[2] <- ceiling(max(dataset[x_axis_variable]))
    }
    
    # initialize the minimum set of counterfactuals (the x-axis variable cuts)
    counterfactuals <- seq(x_range[1], x_range[2], length.out = x_range_density)
    
    # check if a facet variable has been set
    if(!is.null(facet_variable)) {
        # if a facet variable has been set, we expand the counterfactuals
        # to include all x-axis variable/facet variable combinations
        # NOTE: also have to force the factor to numeric for mlogitsimev
        counterfactuals <- expand.grid(counterfactuals, 
                                       as.numeric(unique(dataset[[facet_variable]]))
        )
        names(counterfactuals) <- c(x_axis_variable, facet_variable)
    } else {
        counterfactuals <- expand.grid(counterfactuals)
        names(counterfactuals) <- x_axis_variable
    }
    
    # finally, we check if there are additional predictors...
    variable_names <- all.vars(model_object$call[[2]])
    predictor_names <- variable_names[2:length(variable_names)]
    # by comparing the total number of predictors against the number of columns
    # in the counterfactual table...
    if(length(predictor_names) > ncol(counterfactuals)) {
        # drop out the x-axis and (if used) facet variables...
        if(!is.null(facet_variable)) {
            retained_index <- !grepl(paste(x_axis_variable, facet_variable, sep = "|"), 
                                     predictor_names)
        } else {
            retained_index <- !grepl(x_axis_variable, predictor_names)
        }
        # and gather the "fixed" predictors
        extra_predictors <- predictor_names[retained_index]
        
        # now we get the means for the fixed predictors...
        mean_set <- NULL
        for(i in 1:length(extra_predictors)) {
            mean_set[i] <- mean(as.numeric(dataset[, extra_predictors[i]]), 
                                na.rm = T)
        }
        # and attach those means to the current counterfactual set
        for(i in 1:length(extra_predictors)) {
            counterfactuals <- cbind(counterfactuals, mean_set[i])
        }
        offset_amount <- length(predictor_names) - length(extra_predictors) + 1
        names(counterfactuals)[offset_amount:ncol(counterfactuals)] <- extra_predictors
    }
    
    # we wrap up by returning the counterfactual set
    return(counterfactuals)
}

# simulate expected probabilities using the new data and the coefficients
# NO NEW FUNCTION NEEDED - THIS IS HANDLED BY mlogitsimev

###############################################################################
## FUNCTIONs TO VISUALIZE OUTCOME PREDICTIONS (USER SELECTED X-AXIS/FACETTING)

visualize_predictions <- function(prediction_object, model_object, 
                                  counterfactuals,
                                  x_axis_variable, facet_variable = NULL,
                                  x_lab = "Predictor", y_lab = "p(Outcome)") {
    # the mlogit structure is a collection of arrays but ggplot wants dataframes
    # first we extract the arrays as matrices and bind them together
    num_col <- ncol(prediction_object$lower)
    tidy_sim <- rbind(matrix(prediction_object$lower, ncol = num_col),
                      matrix(prediction_object$upper, ncol = num_col),
                      matrix(prediction_object$pe, ncol = num_col)
    )
    
    # then we format the resulting collection to be properly grouped and
    # labelled for visualizing
    tidy_sim <- data.frame(tidy_sim)
    # the outcome names are retained in the model object - we take these and
    # label our prediction dataframe columns accordingly
    names(tidy_sim) <- model_object$lab
    # add a grouping variable for the three types of measures we get from
    # the prediction object
    tidy_sim$measure_type <- rep(c("lower", "upper", "pe"), 
                                 each = nrow(prediction_object$upper))
    # we also add the predictor (x-axis) value that will link the unique sets
    # (lower, upper, pe) - this should naturally repeat to the appropriate
    # length
    tidy_sim$predictor <- rep(counterfactuals[[x_axis_variable]])
    # finally, if there is a facet variable set, we also add it as a grouping 
    # variable
    if(!is.null(facet_variable)) {
        # factors are also stored in the model object, so we extract
        # from there again
        factor_levels <- model_object$xlevels[[facet_variable]]
        # the number of repitions of the factor is determined by the length
        # of the x_axis variable / number of unique factor levels
        num_reps <- nrow(prediction_object$upper) / length(factor_levels)
        # finally add the grouping variable
        tidy_sim$facet <- rep(factor_levels, each = num_reps)
    }
    print(tidy_sim)
    
    # collapsing and spreading variables to make visualizing easy
    # (this is a tad arbitrary - it is consisent with Brian's interpretation of
    # good ggplot practice)
    if(!is.null(facet_variable)) {
        # if a facet variable is set, respect it...
        tidy_sim <- gather(tidy_sim, outcome, likelihood, -measure_type, 
                           -predictor, -facet)    
    } else {
        # otherwise don't because it's not there
        tidy_sim <- gather(tidy_sim, outcome, likelihood, -measure_type, 
                           -predictor)
    }
    tidy_sim <- spread(tidy_sim, measure_type, likelihood)
    
    # built the plot object
    plot_object <- ggplot(tidy_sim, aes(x = predictor, y = pe, 
                                        group = outcome, 
                                        ymin = lower, ymax = upper)) + 
        geom_line() +
        # takes the ymin and ymax and draws a ribbon around the lines
        geom_ribbon(alpha = 0.5, aes(fill = outcome)) + 
        theme_bw() +
        xlab(x_lab) +
        ylab(y_lab)
    
    # if a facet variable is set, add the facet layer to the plot object
    if(!is.null(facet_variable)) {
        plot_object <- plot_object + facet_wrap(~ facet)
    }
    
    # return the plot object
    return(plot_object)
}

###############################################################################
## TEST WRAPPER (likely cannot use this with Shiny or it will re-run
## the entire function each time an input is changed - NEED TO VERIFY THIS)

test_wrapper <- function(dataset, model_object, 
                         x_axis_variable, facet_variable = NULL,
                         coeff_sample_size = 1000) {
    # create the supporting objects
    pe <- get_point_estimates(model_object)
    cvm <- get_covariance_matrix(model_object)
    ce <- get_coefficient_estimates(coeff_sample_size, pe, cvm, 
                                    length(model_object$lab))
    nd <- get_new_data(dataset, model_object, 
                       x_axis_variable, facet_variable = facet_variable)
    
    # generate the predictions
    prediction_object <- mlogitsimev(nd, ce, ci = 0.67)
    
    # generate the plot object
    plot_object <- visualize_predictions(prediction_object, model_object, 
                                         nd, x_axis_variable, facet_variable)
    # return the plot object
    return(plot_object)
}

###############################################################################